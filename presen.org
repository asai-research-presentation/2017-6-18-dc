#+title: Exploiting Search Space Structure in Classical Planning: Analyses and Algorithms (DC talk)
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: gif file:img/%s.gif
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: sgif file:img/static/%s.gif

#+begin_outline-text-1
#+begin_center
Masataro Asai

Final year in Ph.D program (1 years to go)

University of Tokyo

13 min.
#+end_center

#+begin_note
#+begin_alignright
Made by guicho2.71828 (Masataro Asai)
#+end_alignright
#+end_note
#+end_outline-text-1

* Introduction & Motivation

+ 
  #+begin_larger
  *There are too many algorithms!*

  (A*, LA*, PEA*, GBFS, LS, MRW, MCTS, RRT... LAMA, probe, etc...)
  #+end_larger
  + Theoretical but qualitative property : (Probabilistic) Completeness, Optimality
    + e.g. If it is incomplete, *how* incomplete it is?
  + Lacks the */quantitative continuum/* : How/Why they differ, measured by numbers (not performance)
+ 
  #+begin_larger
  Can we describe the behavior of various algorithms uniquely in a simple measure?
  #+end_larger

* The Problems

+ Different classes of algorithms (optimal vs. satisficing search)
  + Different theoretical requirements
# + The behavior might be affected by the heuristic functions
#   + Not able to discuss the algorithm behavior
# + Simply wide variety of algorithms
#   + Methods for analysis should be sufficiently general

** The beginning: A* tiebreaking (AAAI2016)                        :noexport:

Standard A* OPEN list [f,h,＊] is sorted by lexicographical ordering

+ First sort by $f=g+h$
+ Next sort by $h$ (tiebreaking)
+ ＊ : *Implicitly* sort by FIFO or LIFO or Random (2nd level: /default tiebreaking/)
  + Has tremendous effect on performance on domains where *most edge costs are 0*
  + Because it causes many ties
  + Domains w/ 0-cost edges is harder than $\mathbb{Z}^{\gt 0}$ -cost edges (Aghighi 15,16)

Random Depth Tiebreaking [f,h,<d>,*] : Balanced expansion among *plateau depths*

+ f: First sort by $f=g+h$
+ h: Next sort by $h$
+ <d>: Randomly select a /depth bucket/ : depth = steps from the nearest ancestor with the same f,h
+ ＊ : Implicitly sort by FIFO or LIFO or Random (/default tiebreaking/)

** The beginning: A* tiebreaking (AAAI2016)                        :noexport:

Tiebreaking in A* by balancing the search depth in each plateau → improved performance

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
[[png:aaai16-3]]

Diversified search in each plateau compared to LIFO (=DFS), FIFO (=BrFS)
#+end_span6
#+begin_span6
#+begin_smaller
| /                       | <            | >           | <>                |
|                         | <c>          | <c>         | <c>               |
|                         | ［h, FIFO］  | ［h, LIFO］ | ［h, RD, RO］     |
| Domain Set              | (FD Default) |             | (Proposed)        |
|-------------------------+--------------+-------------+-------------------|
| LMcut                   |              |             |                   |
| IPC Instances (1104)    | 558          | 565         | *572.8* (↑ 14.8) |
| Zerocost Instances(680) | 256          | 279         | *294.2* (↑ 38.2) |
| Sum(1724)               | 814          | 844         | *867.0* (↑ 53.0) |
|-------------------------+--------------+-------------+-------------------|
| M&S                     |              |             |                   |
| IPC Instances (1104)    | 479          | *488*       | 484.0 (↑ 5.0)    |
| Zerocost Instances(680) | 276          | 290         | *310.2* (↑ 34.2) |
| Sum(1724)               | 755          | 778         | *794.2* (↑ 39.2) |
|-------------------------+--------------+-------------+-------------------|
#+end_smaller
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Very similar concept was used for satisficing search, with a different context :noexport:

*Type-GBFS: Search Diversification* method for *GBFS* (satisficing search)

+ Type-based bucket $\langle g, h \rangle$ (Xie 14) ::
  + Store the nodes according to the keys
  + Select a random node in a random bucket for each expansion from the OPEN list
+ Type-GBFS ::
  + Alternate Type-bucket expansion and GBFS expansion
+ RandomDepth (AAAI16) uses type-bucket */within a plateau made by h/* ::
  $[ f, h, \langle d \rangle ]$ --- Similar technique, but for optimal search
  

+ Satisficing Search and Optimising Search
#+begin_xlarge
+ Will it blend? (Yes it does!)
#+end_xlarge

** A* (optimal search) works as follows

Expands the nodes in increasing order of *f* value

[[png:astar/astar1]]

*** A* (optimal search) works as follows

Expands the nodes in increasing order of *f* value

  [[png:astar/astar2]]

*** A* (optimal search) works as follows

Expands the nodes in increasing order of *f* value

  [[png:astar/astar3]]

*** A* (optimal search) works as follows

Expands the nodes in increasing order of *f* value

 [[png:astar/astar4]]

+ *The order of expansion in each plateau* does not matter for the optimality

+ In each plateau, *the path can be arbitrarily long*

#+begin_alignright
#+begin_larger
+ We are runnning a *satisficing search* on each plateau
#+end_larger
#+end_alignright

** Reinterpret A∗ as */iterations of satisficing search on plateaus/* (JAIR17, HSDIP17)

+ A* $[ f, h, \text{fifo} ]$  : Performing *GBFS* $[ h, \text{fifo} ]$ *on each plateau(f)*
+ A* $[ f, \text{fifo} ]$  : *Blind breadth-first search* $[ \text{fifo} ]$ *on each plateau(f)* → slower

#+begin_src bash
while true
    satisficing_search( plateau(f))
    if plateau (f) is SAT; then
       return solution
    else
       Increase f
#+end_src

*** A* as satisficing search (JAIR17, HSDIP17)

 #+begin_src bash
 while true
     satisficing_search( plateau(f))
     if plateau (f) is SAT; then
        return solution
     else
        Increase f
 #+end_src

[[png:sat/sat-astar1]]

*** A* as satisficing search (JAIR17, HSDIP17)

 #+begin_src bash
 while true
     satisficing_search( plateau(f))
     if plateau (f) is SAT; then
        return solution
     else
        Increase f
 #+end_src

[[png:sat/sat-astar2]]

*** A* as satisficing search (JAIR17, HSDIP17)

 #+begin_src bash
 while true
     satisficing_search( plateau(f))
     if plateau (f) is SAT; then
        return solution
     else
        Increase f
 #+end_src

[[png:sat/sat-astar3]]

*** A* as satisficing search (JAIR17, HSDIP17)

#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
 #+begin_src bash
 while true
     satisficing_search( plateau(f))
     if plateau (f) is SAT; then
        return solution
     else
        Increase f
 #+end_src
#+end_span7
#+begin_span5
Implication: 
#+begin_larger
+ *Any complete satisficing technique* can be embedded in optimal planning
#+end_larger
#+end_span5
#+end_row-fluid
#+begin_row-fluid
#+begin_span7
[[png:sat/sat-astar4]]
#+end_span7
#+begin_span5
+ We evaluated several instances and improved the performance
+ Results are optimal as long as *f* is admissible
#+end_span5
#+end_row-fluid
#+end_container-fluid



#+begin_larger
+ Now forget about *optimal*, let's focus on *satisficing*
#+end_larger

* The Problems

+ /Different classes of algorithms (optimal vs. satisficing search)/ *DONE*
  + /Different theoretical requirements/
+ *The behavior might be affected by the heuristic functions*
  + Not able to discuss the algorithm behavior
# + Simply wide variety of algorithms
#   + Methods for analysis should be sufficiently general

** Heuristic Satisficing Search

Less requirements → a *larger* variety of algorithms & ad-hoc ness

| Purposes                   | Approach      | Affect $h$ ? |
|----------------------------+---------------+--------------|
| Minimize the cost of eval. | Lazy Eval     | ○           |
|----------------------------+---------------+--------------|
| Avoid local minima         | Randomization | ✗            |
|----------------------------+---------------+--------------|
| Escaping local minima      | Local Search  | ✗            |
|                            | Preferred Ops | ✗            |
|----------------------------+---------------+--------------|

Lazy Eval == using a different heuristics

Other methods (avoidance, escape) are *Search Diversification*

Thus we focus on *Search Diversification*

** Search Diversification

[[png:diversify/1]]

*** Search Diversification
[[png:diversify/2]]

*** Search Diversification
[[png:diversify/3]]

*** Search Diversification
[[png:diversify/4]]

*** Search Diversification
[[png:diversify/5]]

*** Search Diversification

[[png:diversify/final]]

** Two modes of diversification : Intra-plateau and Inter-plateau (ICAPS17)

[[png:plateau/final]]

Previous work have the mixed effect of both (e.g. GBFS-LE)

** Intra-vs-Inter are orthogonal & complementary

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
[[png:icaps17-results]]
#+end_span6
#+begin_span6
+ With both modes enabled, effects combine
+ Both modes are based on a knowledge-free (blind) method
+ *Now we no longer have to care about heuristics!*
#+end_span6
#+end_row-fluid
#+end_container-fluid

* The Problems

+ /Different classes of algorithms (optimal vs. satisficing search)/ *DONE*
  + /Different theoretical requirements/
+ /The behavior might be affected by the heuristic functions/ *DONE*
  + /Not able to discuss the algorithm behavior/
+ *Simply wide variety of algorithms* 
  + Methods for analysis should be sufficiently general

** Analyzing the blind search behavior

What do we know about blind search? --- not much

+ Search depth, branching factor
+ but they do not describe the actual "shape" of the resulting graph
+ In a representation-independent way --- for continuous domains (e.g. RRT)

[[png:fractals/shape]]

** Fractals

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Infinite fractals

[[sgif:koch]]

[[sgif:sierpinski]]
#+end_span6
#+begin_span6
*Random fractals* (our focus)

[[png:fractals/dla]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Fractal Dimension

A real number characterizing each shape

+ How the number of points react to the different scaling

+ Represent the *sparseness* of a shape wrto space dimension

#+begin_smaller
Note: Complicated /measure theory/ involved, we don't have to deal with the details
#+end_smaller

[[png:fractals/dimention]]

** Bond Invasion Percolation (ICAPS17)

A practical diversification for Classical Planning

　

[[png:fractals/bip]]

** Improves the performance as a diversification method (ICAPS17)

Benchmark on FF heuristic

| Diversified FBFS                   | IPC11+IPC14 score |
|------------------------------------+-------------------|
| Baseline                           |               192 |
| (inter + intra plateau) Type-based |             223.9 |
| (inter + intra plateau) BIP        |           *237.7* |

** Search algorithm == Generator of a (random) fractal

[[png:fractals/eden]]

*** Search algorithm == Generator of a (random) fractal

[[png:fractals/eden-2]]

** Analysing Various Search Algorithms as Fractals

[[png:fractals/fractal3]]

** Example: Understanding the min. sparseness

[[png:fractals/intersection]]

* Conclusion

#+begin_larger
+ Unified Search Theory^{TM}:
  + (*JAIR17*) Optimal search (A*)
    
    #+begin_alignright
    → a sequence of satisficing search
    #+end_alignright
  + (*ICAPS17*) Satisficing heuristic search
    
    #+begin_alignright
    → a combination of blind searches
    #+end_alignright
  + (*ICAPS17+*) Fractal theory: Mathematical tools for blind search
#+end_larger

#+begin_alignright
I have a lot other topics too! (Come to KEPS talk for DLNN+Planning !)
#+end_alignright

* Old materials

** Proposal: Unifying Framework for Analyzing Search Space

[[png:triangle]]

** Proposal: Unifying Framework for Analyzing Search Space

[[png:triangle0]]

** Proposal: Unifying Framework for Analyzing Search Space

[[png:triangle1]]

** 

#+begin_xlarge
#+begin_center
Percolation Theory
#+end_center
#+end_xlarge

*** Percolation Theory                                             :noexport:

  [[png:percolate/circuit]]

*** Example: Percolation in 2-dimentional grids

  A node is either *occupied* or *unoccupied*

  [[png:percolate/percolated0]]

  #+begin_alignright
  #+begin_larger
  + Key interst: *when/how* a graph percolates?
  #+end_larger
  #+end_alignright

*** Bond (edge) / Site (node) percolation

[[sgif:site-bond]]

*** Percolation described by occupation ratio /r/

  [[png:percolate/cluster0]]

*** Percolation described by occupation ratio /r/

  [[png:percolate/cluster1]]

*** Percolation described by occupation ratio /r/

[[png:percolate/cluster2]]

*** Percolation described by occupation ratio /r/

Generates a connected cluster with complex shape

[[png:percolate/cluster3]]

*** Phase Transition

[[png:percolate/cluster4]]

*** Macros may be shifting the ratio to the right

  [[png:percolate/cluster5]]

*** Forward Search : Increasing /r/ as the search progresses

  [[png:percolate/cluster6]]

*** Open Questions

  + *Prove the connection between macro-operators and critical value*
    + I am testing if randomly generated *Junk Macros* improve the performance
      + *Ongoing work --- /positive results/ (next slide)*
  + *How /existing macro-approaches/ change the connectivity?*
    + MacroFF(Botea05), Marvin(Coles04,07) MUM(Chrpa14), CAP(Asai15), BLOMA(Siddiqui15)
  + *What is the /r_c/ of each domain?*
    + critical value of Logistics is X, Barman is Y ...
  + *At which /r/ does each search algorithm find a solution?*
    + Lookahead search, GBFS, Type-GBFS, A*, Random Walk...

**** Preliminary results on Junk Macros

  [[png:percolate/junk]]

  #+begin_alignright
  Promising direction!
  #+end_alignright

** Unifying Framework for Analyzing Search Space

[[png:triangle2]]

** 

#+begin_xlarge
#+begin_center
Fractals
#+end_center
#+end_xlarge

#+begin_alignright
No time, only described briefly
#+end_alignright

*** Fractals 

Sierpinsky's Gasket, Tree (L-system), Koch Curve


#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
[[sgif:sierpinski]]
#+end_span6
#+begin_span6
[[sgif:koch]]
#+end_span6
#+end_row-fluid
#+end_container-fluid


*** Fractal Dimension: How many nodes are included when the */scale/* changes?

Takes Fractional value; != Space Dimension

[[png:fractals/dimention]]

*** Fractals are defined by generative rules: example

  [[png:fractals/ba]]

*** Fractals are defined by generative rules: example

  [[png:fractals/dla]]

*** Fractals are defined by generative rules: example

  [[png:fractals/eden]]

*** */Search space/* is also defined by expansion rules

  [[png:fractals/eden-2]]

*** Connections between Fractals and Search Algorithms

[[png:fractals/fractal]]

*** Connections between Fractals and Search Algorithms

[[png:fractals/fractal2]]

*** Connections between Fractals and Search Algorithms

[[png:fractals/fractal3]]

*** Connections between Fractals and Percolation

  [[png:fractals/cluster]]

** Unifying Framework for Analyzing Search Space

[[png:triangle3]]

** Conclusion: Thesis Abstract

#+begin_larger
+ *Establish a framework* for analysing the search behavior based on percolation theory
+ *Propose paper 1,2,3*
+ *Analyze paper 1,2,3* using *percolation theory*
  + Macro operators in paper 1,2
  + Tiebreaking mechanism in paper 3
+ */Give an answer/ to why paper 1,2,3 perform good*
#+end_larger

#+begin_alignright
→ Unified, consistent thesis!
#+end_alignright

#+begin_larger
#+begin_center
Thank you for listening!
#+end_center
#+end_larger

**             not-used                                            :noexport:

*** Meta-parameter which defines the shape: Fractal dimension

  a statistical index of complexity comparing how detail in a pattern changes with the scale at which it is measured

**** Computing the Fractal Dimension





**** Connections between Fractals and Search Algorithms

   [[png:fractals/fractal]]
*** Possible Benefits:

  + More thoeries about macro operators. Only thing we know:
    + "*Increases branching factor*"
    + *!=* *effective* branching factor by heuristic search
  + Understand Search Algorithms by the *shape of the explored space*
    + What is the fundamental difference between 2 algorithms?
*** Effective Search Space

  Search space evaluated by the search algorithm ⊆ (entire) search space

  [[png:fractals/ess]]

  Each search algorithm defines its */shape/*

*** Inherent Danger of Showing Research Ideas at DC                :noexport:
  
  I am inclined to continuing research after graduation as a PostDoc / maybe in industry, but showing too much
  unreliable ideas here may cause this:

  #+begin_alignright
  (just be sure, I'm *not* claiming I am Einstein, no!)
  #+end_alignright

  [[png:einstein]]

  # + Do you want to hire people with crazy ideas? or
  # + Do you want to hire people with safe ideas?
  # + Depending on the answers, I should not show some part of the slides in this talk
   
